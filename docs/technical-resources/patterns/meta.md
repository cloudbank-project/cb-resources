---
title: Meta
parent: Design Patterns
icon: pattern-security.png
grand_parent: Technical Resources
---

# Meta

We have inclueded this space to list common meta-practices / meta-design with (a) brief remarks on utility and (b) references we have found useful.
Some of this content has direct relevance to data science collaboration: Good ideas irrespective of cloud use. In fact let's be very clear:
This is research computing methods advocacy. Cloud computing happens to be part of that and it is our strong suit; but cloud is just one of 
the many roads that leads to Rome. Where Rome in this metaphor is the place a researcher wants to be: Concentrating on the research, 
not the supporting infrastructure.


## Learning curves and time investment

The list of topics that follows can appear intimidating. Not surprisingly the main condition of success is
being able to make time: First to understand the landscape that we sketch here, and second to incorporate
the ideas and skills into your research process. To this end it is a Bad News Good News situation in our
view. The Bad News is that there is no substitute for clearing away all distractions and focusing for an 
extended period (days / weeks / months) on building these new skills. The Good News is that we are in a 
boom era for excellent learning materials, reference documents, and help debugging mysterious errors.


As we value useful details, let's state one here. Copying and pasting error messages into your browser
search window is a surprisingly effective tool because of the existence of "knowledge base" websites such 
as Stack Overflow. 

## Demand good training!

By this we mean: Imagine you want to learn how to analyze dolphin calls as they would sound in the oceans of Europa. 
There is *probably* a really good YouTube training seminar on just this topic... so finding it is the trick. Often 
this requires a bit of diligence and maybe some skill with the search terms. As a more concrete example we found
[this](https://regexone.com/) training resource on learning how to work with **regular expressions**. Super powerful
if you work with text interpretation and parsing, say in NLP. So we put that link below. If you 
find a good resource: Tell us so we can put it here!

## Linux

## The shell

## Software versioning and `git`

## GitHub and GitLab

## Jupyter notebooks

## Environments and Environment Bootstrapping

## Binder sandboxes

## Integrating and harmonizing notebooks: Jupyter Books

## More on git: Clones in relation to Forks

## More on Jupyter 1: Commonly used Python libraries for meta-tasks

- Pickle: An easy way to share data structures across notebooks. [Here is an introductory blog.](https://betterprogramming.pub/dont-fear-the-pickle-using-pickle-dump-and-pickle-load-5212f23dbbce)
    - Notebooks tend to grow until they become unwieldy. A natural step is to break them down into smaller conceptual blocks. 
    - Pickle facilitates 'picking up where the previous notebook left off'.
    - Warning: Not necessarily cross-platform
    - Rejoice: Checkpointing! Cloud cost savings!
- Up your game to JSON!

## More on Jupyter 2: Magic

## More on Jupyter 3: Hubs, Littlest

## More on Jupyter 4: How the cloud plays in

## Jupyter for Education

[Here](https://jupyter4edu.github.io/jupyter-edu-book/case-studies.html)

## Natural Language Processing 1: Where to begin

- The Jupyter environment as noted is suitable for many data science sub-disciplines. Natural Language Processing (NLP) is no exception.
    - [This tutorial video provides an excellent introduction to the topic]

- 

## Regular Expressions

A regular expression is a formalism for parsing text. Learn how to do it [here](https://regexone.com/).

## The Cloud 1: What are the key differences?
